{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2030eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e573082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 193263_0_time.npy : 첫 열 내용 ===\n",
      "[datetime.date(2020, 6, 10) datetime.date(2020, 6, 11)\n",
      " datetime.date(2020, 6, 12) datetime.date(2020, 6, 13)\n",
      " datetime.date(2020, 6, 14) datetime.date(2020, 6, 15)\n",
      " datetime.date(2020, 6, 16) datetime.date(2020, 6, 17)\n",
      " datetime.date(2020, 6, 18) datetime.date(2020, 6, 19)\n",
      " datetime.date(2020, 6, 20) datetime.date(2020, 6, 21)\n",
      " datetime.date(2020, 6, 22) datetime.date(2020, 6, 23)\n",
      " datetime.date(2020, 6, 24) datetime.date(2020, 6, 25)\n",
      " datetime.date(2020, 6, 26) datetime.date(2020, 6, 27)\n",
      " datetime.date(2020, 6, 28) datetime.date(2020, 6, 29)\n",
      " datetime.date(2020, 6, 30) datetime.date(2020, 7, 1)\n",
      " datetime.date(2020, 7, 2) datetime.date(2020, 7, 3)\n",
      " datetime.date(2020, 7, 4) datetime.date(2020, 7, 5)\n",
      " datetime.date(2020, 7, 6) datetime.date(2020, 7, 7)\n",
      " datetime.date(2020, 7, 8) datetime.date(2020, 7, 9)\n",
      " datetime.date(2020, 7, 10) datetime.date(2020, 7, 11)\n",
      " datetime.date(2020, 7, 12) datetime.date(2020, 7, 13)\n",
      " datetime.date(2020, 7, 14) datetime.date(2020, 7, 15)\n",
      " datetime.date(2020, 7, 16) datetime.date(2020, 7, 17)\n",
      " datetime.date(2020, 7, 18) datetime.date(2020, 7, 19)\n",
      " datetime.date(2020, 7, 20) datetime.date(2020, 7, 22)\n",
      " datetime.date(2020, 7, 23) datetime.date(2020, 7, 24)\n",
      " datetime.date(2020, 7, 25) datetime.date(2020, 7, 26)\n",
      " datetime.date(2020, 7, 27) datetime.date(2020, 7, 28)\n",
      " datetime.date(2020, 7, 29) datetime.date(2020, 7, 30)\n",
      " datetime.date(2020, 7, 31) datetime.date(2020, 8, 1)]\n",
      "\n",
      "=== 193263_0.npy : 첫 열 내용 ===\n",
      "[[226]\n",
      " [118]\n",
      " [147]\n",
      " [ 91]\n",
      " [217]\n",
      " [188]\n",
      " [ 90]\n",
      " [ 78]\n",
      " [172]\n",
      " [ 61]\n",
      " [113]\n",
      " [ 80]\n",
      " [240]\n",
      " [139]\n",
      " [171]\n",
      " [ 88]\n",
      " [137]\n",
      " [126]\n",
      " [134]\n",
      " [227]\n",
      " [252]\n",
      " [112]\n",
      " [214]\n",
      " [185]\n",
      " [109]\n",
      " [191]\n",
      " [241]\n",
      " [109]\n",
      " [185]\n",
      " [195]\n",
      " [293]\n",
      " [168]\n",
      " [118]\n",
      " [163]\n",
      " [123]\n",
      " [140]\n",
      " [195]\n",
      " [290]\n",
      " [132]\n",
      " [154]\n",
      " [171]\n",
      " [400]\n",
      " [225]\n",
      " [137]\n",
      " [177]\n",
      " [125]\n",
      " [165]\n",
      " [108]\n",
      " [191]\n",
      " [154]\n",
      " [ 88]\n",
      " [186]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) 파일 경로 지정\n",
    "time_fp = \"T1_granada_time/193263_0_time.npy\"\n",
    "data_fp = \"T1_granada/193263_0.npy\"\n",
    "\n",
    "# 2) .npy 파일 로드 (datetime 배열 또는 숫자 배열)\n",
    "time_arr = np.load(time_fp, allow_pickle=True)\n",
    "data_arr = np.load(data_fp, allow_pickle=True)\n",
    "\n",
    "# 3) 첫 열만 추출/출력\n",
    "def print_first_column(arr, name):\n",
    "    print(f\"=== {name} : 첫 열 내용 ===\")\n",
    "    if arr.ndim == 1:\n",
    "        # 1D array는 곧 첫 열 전체\n",
    "        print(arr)\n",
    "    else:\n",
    "        # 2D 이상 배열인 경우 첫 열만\n",
    "        print(arr[:, 0])\n",
    "    print()\n",
    "\n",
    "print_first_column(time_arr, \"193263_0_time.npy\")\n",
    "print_first_column(data_arr, \"193263_0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "034f3729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Span Lengths for LIB193263 ===\n",
      "       id  continuous_data_index  length\n",
      "LIB193263                      0      52\n",
      "LIB193263                      1      26\n",
      "LIB193263                      2      37\n",
      "LIB193263                      3      82\n",
      "LIB193263                      4      13\n",
      "LIB193263                      5       8\n",
      "LIB193263                      6      40\n",
      "LIB193263                      7      26\n",
      "LIB193263                      8      26\n",
      "LIB193263                      9      26\n",
      "LIB193263                     10      79\n",
      "LIB193263                     11      70\n",
      "LIB193263                     12      26\n",
      "LIB193263                     13      39\n",
      "LIB193263                     14      67\n",
      "\n",
      "Summary for LIB193263:\n",
      "- Shortest continuous span: 8 days\n",
      "- Number of spans ≥ 7 days: 15\n",
      "- Number of spans ≥ 14 days: 13\n",
      "- Has at least one span ≥ 7 days? True\n",
      "- Has at least one span ≥ 14 days? True\n"
     ]
    }
   ],
   "source": [
    "# 1. Load demographic data\n",
    "demographic = pd.read_csv(\"T1DiabetesGranada_demographic.csv\")\n",
    "\n",
    "# 2. Identify LIB193263 spans files\n",
    "span_files = sorted(glob.glob(\"T1_granada_time/193263_*_time.npy\"))\n",
    "\n",
    "# 3. Compute span lengths\n",
    "span_records = []\n",
    "for idx, fpath in enumerate(span_files):\n",
    "    arr = np.load(fpath, allow_pickle=True)\n",
    "    length_days = arr.shape[0]\n",
    "    span_records.append({\n",
    "        \"id\": \"LIB193263\",\n",
    "        \"continuous_data_index\": idx,\n",
    "        \"length\": length_days\n",
    "    })\n",
    "\n",
    "spans_df = pd.DataFrame(span_records)\n",
    "\n",
    "# 4. Calculate summary metrics\n",
    "shortest_span = spans_df[\"length\"].min()\n",
    "has_at_least_7 = (spans_df[\"length\"] >= 7).any()\n",
    "has_at_least_14 = (spans_df[\"length\"] >= 14).any()\n",
    "count_spans_ge_7 = (spans_df[\"length\"] >= 7).sum()\n",
    "count_spans_ge_14 = (spans_df[\"length\"] >= 14).sum()\n",
    "\n",
    "# 5. Update demographic for LIB193263\n",
    "demographic.loc[demographic[\"Patient_ID\"] == \"LIB193263\", \"shortest_span_days\"] = shortest_span\n",
    "\n",
    "# 6. Display results\n",
    "print(\"=== Span Lengths for LIB193263 ===\")\n",
    "print(spans_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nSummary for LIB193263:\")\n",
    "print(f\"- Shortest continuous span: {shortest_span} days\")\n",
    "print(f\"- Number of spans ≥ 7 days: {count_spans_ge_7}\")\n",
    "print(f\"- Number of spans ≥ 14 days: {count_spans_ge_14}\")\n",
    "print(f\"- Has at least one span ≥ 7 days? {has_at_least_7}\")\n",
    "print(f\"- Has at least one span ≥ 14 days? {has_at_least_14}\")\n",
    "\n",
    "# 7. (Optionally) Save outputs\n",
    "# spans_df.to_csv(\"LIB193263_continuous_spans.csv\", index=False)\n",
    "# demographic.to_csv(\"demographic_updated.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68b0ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All spans pass date‐vector validation (gaps ≤ 2 days).\n"
     ]
    }
   ],
   "source": [
    "# 1) Load all span files for subject 193263\n",
    "span_files = sorted(glob.glob(\"T1_granada_time/193263_*_time.npy\"))\n",
    "all_good = True\n",
    "\n",
    "for idx, fp in enumerate(span_files):\n",
    "    arr = np.load(fp, allow_pickle=True)  # Python datetime array\n",
    "    \n",
    "    # 2) Compute day‐wise gaps between consecutive entries using .days\n",
    "    #    gaps[i] = number of days between arr[i] and arr[i+1]\n",
    "    gaps = [(arr[i+1] - arr[i]).days for i in range(len(arr) - 1)]\n",
    "    \n",
    "    # 3) Identify any gap > 2 days (tolerance: up to 2 days is OK)\n",
    "    bad_gaps = [g for g in gaps if g > 2]\n",
    "    if bad_gaps:\n",
    "        # Report which span and what distinct gaps were too large\n",
    "        print(f\"Span {idx} has excessive date gaps: {set(bad_gaps)} days\")\n",
    "        all_good = False\n",
    "\n",
    "if all_good:\n",
    "    print(\"All spans pass date‐vector validation (gaps ≤ 2 days).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "18353aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일명                                      시작일          종료일              엔트리수\n",
      "---------------------------------------------------------------------------\n",
      "193263_0_time.npy                        2020-06-10   2020-08-01         52\n",
      "193263_10_time.npy                       2021-09-26   2021-10-22         26\n",
      "193263_11_time.npy                       2021-10-24   2021-11-30         37\n",
      "193263_12_time.npy                       2021-12-02   2022-02-22         82\n",
      "193263_13_time.npy                       2022-02-24   2022-03-08         13\n",
      "193263_14_time.npy                       2022-03-11   2022-03-18          8\n",
      "193263_1_time.npy                        2020-08-04   2020-09-12         40\n",
      "193263_2_time.npy                        2020-09-15   2020-10-10         26\n",
      "193263_3_time.npy                        2020-10-13   2020-11-07         26\n",
      "193263_4_time.npy                        2020-11-10   2020-12-05         26\n",
      "193263_5_time.npy                        2020-12-08   2021-02-24         79\n",
      "193263_6_time.npy                        2021-02-27   2021-05-08         70\n",
      "193263_7_time.npy                        2021-05-10   2021-06-05         26\n",
      "193263_8_time.npy                        2021-06-07   2021-07-16         39\n",
      "193263_9_time.npy                        2021-07-19   2021-09-24         67\n"
     ]
    }
   ],
   "source": [
    "# 1) 시간 벡터 파일 목록 불러오기\n",
    "time_files = sorted(glob.glob(\"T1_granada_time/193263_*_time.npy\"))\n",
    "\n",
    "print(f\"{'파일명':40s} {'시작일':12s} {'종료일':12s} {'엔트리수':>8s}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for fp in time_files:\n",
    "    # 2) numpy 로드 (python datetime.date 배열)\n",
    "    arr = np.load(fp, allow_pickle=True)\n",
    "    \n",
    "    # 3) 시작·종료 날짜 추출 (datetime.date 객체)\n",
    "    start_date = arr.min()   # already a datetime.date\n",
    "    end_date   = arr.max()\n",
    "    \n",
    "    # 4) 엔트리 수(일수)\n",
    "    entry_count = len(arr)\n",
    "    \n",
    "    # 5) 결과 출력\n",
    "    filename = os.path.basename(fp)\n",
    "    print(f\"{filename:40s} {start_date:%Y-%m-%d}   {end_date:%Y-%m-%d}   {entry_count:8d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "676c9a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.897551e+07\n",
      "mean     1.741869e+01\n",
      "std      3.207608e+02\n",
      "min      0.000000e+00\n",
      "25%      1.500000e+01\n",
      "50%      1.500000e+01\n",
      "75%      1.500000e+01\n",
      "max      3.809030e+05\n",
      "Name: diff_min, dtype: float64\n",
      "diff_min\n",
      "10       27691\n",
      "11       32111\n",
      "12       37058\n",
      "13       43007\n",
      "14      252363\n",
      "15    17172491\n",
      "16      763000\n",
      "17      136677\n",
      "18       35975\n",
      "19       10557\n",
      "20        2299\n",
      "21         382\n",
      "22         125\n",
      "23         411\n",
      "24         416\n",
      "25         321\n",
      "26          68\n",
      "27          38\n",
      "28          77\n",
      "29         711\n",
      "30        7807\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1) 파일 읽기\n",
    "df = pd.read_csv('T1_granada_filtered.csv', parse_dates=['time'])\n",
    "\n",
    "# 2) 환자별로 시간 차 계산 (분 단위)\n",
    "df['diff_min'] = df.groupby('id')['time'].diff().dt.total_seconds() / 60\n",
    "\n",
    "# 3) 전체 간격별 빈도 계산\n",
    "counts = df['diff_min'].value_counts().sort_index()\n",
    "\n",
    "# 4) 10분부터 30분까지, 각 분별 건수 추출 (없으면 0으로)\n",
    "minutes = list(range(10, 31))\n",
    "counts_10_30 = counts.reindex(minutes, fill_value=0)\n",
    "\n",
    "# 3) 전체 구간의 통계\n",
    "print(df['diff_min'].describe())\n",
    "\n",
    "# 5) 결과 출력\n",
    "print(counts_10_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9439c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Precise CSV Analysis for LIB193263 ===\n",
      "                 start                 end  duration_days\n",
      "0  2020-06-09 19:08:00 2020-07-21 18:04:00      41.955556\n",
      "1  2020-07-21 22:18:00 2020-08-02 20:11:00      11.911806\n",
      "2  2020-08-03 00:06:00 2020-09-13 19:45:00      41.818750\n",
      "3  2020-09-14 00:33:00 2020-10-11 19:50:00      27.803472\n",
      "4  2020-10-12 00:49:00 2020-11-08 19:36:00      27.782639\n",
      "5  2020-11-09 00:06:00 2020-12-06 19:35:00      27.811806\n",
      "6  2020-12-07 00:09:00 2021-02-25 19:40:00      80.813194\n",
      "7  2021-02-26 00:11:00 2021-04-25 13:33:00      58.556944\n",
      "8  2021-04-25 16:54:00 2021-05-09 13:43:00      13.867361\n",
      "9  2021-05-09 16:56:00 2021-05-23 13:33:00      13.859028\n",
      "10 2021-05-23 17:53:00 2021-06-06 13:35:00      13.820833\n",
      "11 2021-06-06 17:55:00 2021-06-20 13:32:00      13.817361\n",
      "12 2021-06-20 17:56:00 2021-07-17 23:55:00      27.249306\n",
      "13 2021-07-18 03:03:00 2021-08-14 12:39:00      27.400000\n",
      "14 2021-08-14 15:47:00 2021-10-09 13:32:00      55.906250\n",
      "15 2021-10-09 16:43:00 2021-10-23 13:30:00      13.865972\n",
      "16 2021-10-23 18:50:00 2021-11-06 13:37:00      13.782639\n",
      "17 2021-11-06 18:56:00 2021-12-01 13:38:00      24.779167\n",
      "18 2021-12-01 18:34:00 2022-01-26 16:38:00      55.919444\n",
      "19 2022-01-26 20:53:00 2022-02-23 16:44:00      27.827083\n",
      "20 2022-02-23 20:58:00 2022-03-09 23:45:00      14.115972\n",
      "21 2022-03-10 09:00:00 2022-03-19 07:32:00       8.938889\n",
      "Number of spans ≥ 7 days:  22\n",
      "Number of spans ≥ 14 days: 14\n",
      "Has ≥7-day span?  True\n",
      "Has ≥14-day span? True\n"
     ]
    }
   ],
   "source": [
    "# precise_from_csv_193263.py\n",
    "# -----------------------------------------------------------------------------\n",
    "# Part 1: Identify continuous CGM spans for patient LIB193263\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# 1) Load the CSV into a pandas DataFrame, parsing the 'time' column as datetimes\n",
    "df = pd.read_csv(\"T1_granada_filtered.csv\", parse_dates=[\"time\"])\n",
    "\n",
    "#    Then filter to only keep rows for patient with id \"LIB193263\",\n",
    "#    sort chronologically by 'time', and reset the DataFrame index\n",
    "df = (\n",
    "    df[df.id == \"LIB193263\"]\n",
    "    .sort_values(\"time\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 2) Compute the time difference between each reading and the one before it\n",
    "#    The result is a pandas Timedelta column named 'diff'\n",
    "df[\"diff\"] = df[\"time\"].diff()\n",
    "\n",
    "# 3) Mark the start of a new “continuous” segment whenever the gap exceeds 180 minutes\n",
    "#    - df[\"new_seg\"] is True at the first reading after a gap > 180 minutes\n",
    "#    - fillna(False) ensures the very first row isn’t marked as a new segment\n",
    "timesegment = 180\n",
    "df[\"new_seg\"] = (df[\"diff\"] > timedelta(minutes=timesegment)).fillna(False)\n",
    "\n",
    "#    Cumulatively sum those True flags to assign a unique segment_id to each block\n",
    "df[\"segment_id\"] = df[\"new_seg\"].cumsum()\n",
    "\n",
    "# 4) For each continuous segment, compute:\n",
    "#      - start: timestamp of the first reading\n",
    "#      - end:   timestamp of the last reading\n",
    "#      - count: number of readings in that segment\n",
    "segs = (\n",
    "    df.groupby(\"segment_id\")[\"time\"]\n",
    "      .agg(start=\"first\", end=\"last\", count=\"size\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "#    Then compute the duration of each segment in days:\n",
    "#    (end - start).total_seconds() / 86400 converts seconds to days\n",
    "segs[\"duration_days\"] = (\n",
    "    segs[\"end\"] - segs[\"start\"]\n",
    ").dt.total_seconds() / 86400.0\n",
    "\n",
    "# 5) Count how many segments last at least 7 days and at least 14 days\n",
    "num_ge7  = (segs[\"duration_days\"] >=  7.0).sum()\n",
    "num_ge14 = (segs[\"duration_days\"] >= 14.0).sum()\n",
    "\n",
    "#    Determine whether any such long spans exist for this patient\n",
    "has_ge7  = num_ge7  > 0\n",
    "has_ge14 = num_ge14 > 0\n",
    "\n",
    "# 6) Print out a report summarizing each segment’s start, end, and duration,\n",
    "#    plus the counts of spans ≥ 7 days and ≥ 14 days\n",
    "print(\"=== Precise CSV Analysis for LIB193263 ===\")\n",
    "print(segs[[\"start\", \"end\", \"duration_days\"]])\n",
    "print(f\"Number of spans ≥ 7 days:  {num_ge7}\")\n",
    "print(f\"Number of spans ≥ 14 days: {num_ge14}\")\n",
    "print(f\"Has ≥7-day span?  {has_ge7}\")\n",
    "print(f\"Has ≥14-day span? {has_ge14}\")\n",
    "\n",
    "# 7) (Optional) Save the segment table to a new CSV for later inspection\n",
    "#    Uncomment the lines below to output a file named\n",
    "#    \"LIB193263_precise_spans.csv\" containing segment index, start, end, and duration.\n",
    "# segs = segs.reset_index().rename(columns={\"index\": \"continuous_data_index\"})\n",
    "# segs[[\"continuous_data_index\", \"start\", \"end\", \"duration_days\"]].to_csv(\n",
    "#     \"LIB193263_precise_spans.csv\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0bf3db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects with ≥7-day span:  561\n",
      "Number of subjects with ≥14-day span: 495\n",
      "continuous_spans_details.csv and demographic_with_span.csv generated.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load demographic data\n",
    "# ----------------------------------------------------------------\n",
    "demographic = pd.read_csv(\"T1DiabetesGranada_demographic.csv\")\n",
    "\n",
    "# 2. Find all span files in T1_granada_time\n",
    "#    Filenames like \"193263_0_time.npy\", \"193263_1_time.npy\", ...\n",
    "# ----------------------------------------------------------------\n",
    "span_files = sorted(glob.glob(\"T1_granada_time/*_time.npy\"))\n",
    "\n",
    "# 3. Build a list of span records for every subject\n",
    "# ----------------------------------------------------------------\n",
    "span_records = []\n",
    "for fp in span_files:\n",
    "    # Extract filename, e.g. \"193263_0_time.npy\"\n",
    "    fname = os.path.basename(fp)\n",
    "    parts = fname.split(\"_\")\n",
    "    subj_num = parts[0]               # e.g. \"193263\"\n",
    "    span_idx = int(parts[1])          # e.g. 0, 1, 2, ...\n",
    "    subject_id = \"LIB\" + subj_num     # match the format in demographic\n",
    "\n",
    "    # Load the numpy date‐vector (one entry per day of continuous data)\n",
    "    arr = np.load(fp, allow_pickle=True)  \n",
    "\n",
    "    # Length in days = number of entries\n",
    "    length_days = arr.shape[0]\n",
    "\n",
    "    span_records.append({\n",
    "        \"id\": subject_id,\n",
    "        \"continuous_data_index\": span_idx,\n",
    "        \"length\": length_days\n",
    "    })\n",
    "\n",
    "# Turn into DataFrame\n",
    "spans_df = pd.DataFrame(span_records)\n",
    "\n",
    "# 4. Summary: how many subjects have ≥7d spans, ≥14d spans?\n",
    "# ----------------------------------------------------------------\n",
    "# subjects with any span ≥7 days\n",
    "num_subjects_ge7  = spans_df.loc[spans_df[\"length\"] >=  7, \"id\"].nunique()\n",
    "# subjects with any span ≥14 days\n",
    "num_subjects_ge14 = spans_df.loc[spans_df[\"length\"] >= 14, \"id\"].nunique()\n",
    "\n",
    "print(f\"Number of subjects with ≥7-day span:  {num_subjects_ge7}\")\n",
    "print(f\"Number of subjects with ≥14-day span: {num_subjects_ge14}\")\n",
    "\n",
    "# 5. For each subject, find their shortest continuous span\n",
    "# ----------------------------------------------------------------\n",
    "shortest_per_subject = (\n",
    "    spans_df\n",
    "    .groupby(\"id\")[\"length\"]\n",
    "    .min()\n",
    "    .reset_index(name=\"shortest_span_days\")\n",
    ")\n",
    "\n",
    "# 6. Merge that into demographic\n",
    "# ----------------------------------------------------------------\n",
    "# assume demographic has column \"Patient_ID\" matching \"LIBxxxxx\"\n",
    "dem_updated = pd.merge(\n",
    "    demographic,\n",
    "    shortest_per_subject,\n",
    "    how=\"left\",\n",
    "    left_on=\"Patient_ID\",\n",
    "    right_on=\"id\"\n",
    ")\n",
    "# drop the extra 'id' column\n",
    "dem_updated = dem_updated.drop(columns=[\"id\"])\n",
    "\n",
    "# 7. Save outputs\n",
    "# ----------------------------------------------------------------\n",
    "# Detailed spans for all subjects\n",
    "spans_df.to_csv(\"continuous_spans_details.csv\", index=False)\n",
    "# Updated demographics with shortest span info\n",
    "dem_updated.to_csv(\"demographic_with_span.csv\", index=False)\n",
    "\n",
    "print(\"continuous_spans_details.csv and demographic_with_span.csv generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2701c34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일명                            시작 시각                종료 시각               \n",
      "----------------------------------------------------------------------\n",
      "193263_0_time.npy              2020-06-09 19:08:00  2020-07-21 18:04:00 \n",
      "193263_1_time.npy              2020-07-21 22:18:00  2020-08-02 20:11:00 \n",
      "193263_2_time.npy              2020-08-03 00:06:00  2020-09-13 19:45:00 \n",
      "193263_3_time.npy              2020-09-14 00:33:00  2020-10-11 19:50:00 \n",
      "193263_4_time.npy              2020-10-12 00:49:00  2020-11-08 19:36:00 \n",
      "193263_5_time.npy              2020-11-09 00:06:00  2020-12-06 19:35:00 \n",
      "193263_6_time.npy              2020-12-07 00:09:00  2021-02-25 19:40:00 \n",
      "193263_7_time.npy              2021-02-26 00:11:00  2021-04-25 13:33:00 \n",
      "193263_8_time.npy              2021-04-25 16:54:00  2021-05-09 13:43:00 \n",
      "193263_9_time.npy              2021-05-09 16:56:00  2021-05-23 13:33:00 \n",
      "193263_10_time.npy             2021-05-23 17:53:00  2021-06-06 13:35:00 \n",
      "193263_11_time.npy             2021-06-06 17:55:00  2021-06-20 13:32:00 \n",
      "193263_12_time.npy             2021-06-20 17:56:00  2021-07-17 23:55:00 \n",
      "193263_13_time.npy             2021-07-18 03:03:00  2021-08-14 12:39:00 \n",
      "193263_14_time.npy             2021-08-14 15:47:00  2021-10-09 13:32:00 \n",
      "193263_15_time.npy             2021-10-09 16:43:00  2021-10-23 13:30:00 \n",
      "193263_16_time.npy             2021-10-23 18:50:00  2021-11-06 13:37:00 \n",
      "193263_17_time.npy             2021-11-06 18:56:00  2021-12-01 13:38:00 \n",
      "193263_18_time.npy             2021-12-01 18:34:00  2022-01-26 16:38:00 \n",
      "193263_19_time.npy             2022-01-26 20:53:00  2022-02-23 16:44:00 \n",
      "193263_20_time.npy             2022-02-23 20:58:00  2022-03-09 23:45:00 \n",
      "193263_21_time.npy             2022-03-10 09:00:00  2022-03-19 07:32:00 \n",
      "총 22개의 span을 'T1_granada_time_193263'에 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 1) 원시 CSV 로드 및 환자 필터링\n",
    "df = pd.read_csv(\"T1_granada_filtered.csv\", parse_dates=[\"time\"])\n",
    "subdf = (\n",
    "    df[df.id == \"LIB193263\"]\n",
    "    .sort_values(\"time\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 2) 인접 측정 간격(분) 계산\n",
    "#    diffs[i] = time[i] – time[i-1] (min 단위)\n",
    "diffs = subdf[\"time\"].diff().dt.total_seconds().div(60)\n",
    "\n",
    "# 3) 180분 초과시 새로운 세그먼트 시작\n",
    "threshold_min = 180\n",
    "subdf[\"span_id\"] = (diffs > threshold_min).cumsum()\n",
    "\n",
    "# 4) 출력용 디렉토리 생성\n",
    "out_dir = \"T1_granada_time_193263\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 5) span별로 시작·종료 시각 추출 → npy 파일로 저장\n",
    "print(f\"{'파일명':30s} {'시작 시각':20s} {'종료 시각':20s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for span_idx, grp in subdf.groupby(\"span_id\", sort=True):\n",
    "    # 각 span의 첫·마지막 time 값 (numpy datetime64[ns])\n",
    "    start_ts = grp[\"time\"].iloc[0]\n",
    "    end_ts   = grp[\"time\"].iloc[-1]\n",
    "    # 두 개의 타임스탬프를 담은 1차원 배열\n",
    "    arr = np.array([start_ts.to_datetime64(), end_ts.to_datetime64()])\n",
    "    \n",
    "    fn = f\"193263_{span_idx}_time.npy\"\n",
    "    np.save(os.path.join(out_dir, fn), arr)\n",
    "    \n",
    "    # 사람이 보기 쉽게 출력 (YYYY-MM-DD HH:MM:SS)\n",
    "    start_str = start_ts.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    end_str   = end_ts.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"{fn:30s} {start_str:20s} {end_str:20s}\")\n",
    "\n",
    "print(f\"총 {subdf['span_id'].nunique()}개의 span을 '{out_dir}'에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e123aed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일명                                      시작시각              종료시각                  엔트리수\n",
      "------------------------------------------------------------------------------------------\n",
      "193263_0_time.npy                        2020-06-09 19:08   2020-07-21 18:04          2\n",
      "193263_10_time.npy                       2021-05-23 17:53   2021-06-06 13:35          2\n",
      "193263_11_time.npy                       2021-06-06 17:55   2021-06-20 13:32          2\n",
      "193263_12_time.npy                       2021-06-20 17:56   2021-07-17 23:55          2\n",
      "193263_13_time.npy                       2021-07-18 03:03   2021-08-14 12:39          2\n",
      "193263_14_time.npy                       2021-08-14 15:47   2021-10-09 13:32          2\n",
      "193263_15_time.npy                       2021-10-09 16:43   2021-10-23 13:30          2\n",
      "193263_16_time.npy                       2021-10-23 18:50   2021-11-06 13:37          2\n",
      "193263_17_time.npy                       2021-11-06 18:56   2021-12-01 13:38          2\n",
      "193263_18_time.npy                       2021-12-01 18:34   2022-01-26 16:38          2\n",
      "193263_19_time.npy                       2022-01-26 20:53   2022-02-23 16:44          2\n",
      "193263_1_time.npy                        2020-07-21 22:18   2020-08-02 20:11          2\n",
      "193263_20_time.npy                       2022-02-23 20:58   2022-03-09 23:45          2\n",
      "193263_21_time.npy                       2022-03-10 09:00   2022-03-19 07:32          2\n",
      "193263_2_time.npy                        2020-08-03 00:06   2020-09-13 19:45          2\n",
      "193263_3_time.npy                        2020-09-14 00:33   2020-10-11 19:50          2\n",
      "193263_4_time.npy                        2020-10-12 00:49   2020-11-08 19:36          2\n",
      "193263_5_time.npy                        2020-11-09 00:06   2020-12-06 19:35          2\n",
      "193263_6_time.npy                        2020-12-07 00:09   2021-02-25 19:40          2\n",
      "193263_7_time.npy                        2021-02-26 00:11   2021-04-25 13:33          2\n",
      "193263_8_time.npy                        2021-04-25 16:54   2021-05-09 13:43          2\n",
      "193263_9_time.npy                        2021-05-09 16:56   2021-05-23 13:33          2\n"
     ]
    }
   ],
   "source": [
    "# 1) 시간 벡터 파일 목록 불러오기\n",
    "time_files = sorted(glob.glob(\"T1_granada_time_193263/193263_*_time.npy\"))\n",
    "\n",
    "# 2) 헤더 출력 (시작·종료 시각이 분 단위까지 보이도록 칼럼명 수정)\n",
    "print(f\"{'파일명':40s} {'시작시각':17s} {'종료시각':17s} {'엔트리수':>8s}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for fp in time_files:\n",
    "    # 3) numpy 로드 (python datetime.datetime 객체 배열 또는 numpy.datetime64 배열)\n",
    "    arr = np.load(fp, allow_pickle=True)\n",
    "\n",
    "    # 4) 시작·종료 시각 추출 (datetime.datetime 또는 numpy.datetime64)\n",
    "    start_dt = arr.min()\n",
    "    end_dt   = arr.max()\n",
    "\n",
    "    # 5) 엔트리 수\n",
    "    entry_count = len(arr)\n",
    "\n",
    "    # 6) 결과 출력: 분 단위까지 포맷팅\n",
    "    filename = os.path.basename(fp)\n",
    "    # 만약 arr 요소가 numpy.datetime64이면 to_pydatetime()으로 변환\n",
    "    if isinstance(start_dt, np.datetime64):\n",
    "        start_dt = start_dt.astype('M8[m]').astype('O')\n",
    "        end_dt   = end_dt.astype('M8[m]').astype('O')\n",
    "\n",
    "    print(f\"{filename:40s} \"\n",
    "          f\"{start_dt:%Y-%m-%d %H:%M}   \"\n",
    "          f\"{end_dt:%Y-%m-%d %H:%M}   \"\n",
    "          f\"{entry_count:8d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0f1dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일명                                      시작시각              종료시각                  엔트리수\n",
      "------------------------------------------------------------------------------------------\n",
      "193263_0_time.npy                        2020-06-10 00:00   2020-08-01 00:00         52\n",
      "193263_10_time.npy                       2021-09-26 00:00   2021-10-22 00:00         26\n",
      "193263_11_time.npy                       2021-10-24 00:00   2021-11-30 00:00         37\n",
      "193263_12_time.npy                       2021-12-02 00:00   2022-02-22 00:00         82\n",
      "193263_13_time.npy                       2022-02-24 00:00   2022-03-08 00:00         13\n",
      "193263_14_time.npy                       2022-03-11 00:00   2022-03-18 00:00          8\n",
      "193263_1_time.npy                        2020-08-04 00:00   2020-09-12 00:00         40\n",
      "193263_2_time.npy                        2020-09-15 00:00   2020-10-10 00:00         26\n",
      "193263_3_time.npy                        2020-10-13 00:00   2020-11-07 00:00         26\n",
      "193263_4_time.npy                        2020-11-10 00:00   2020-12-05 00:00         26\n",
      "193263_5_time.npy                        2020-12-08 00:00   2021-02-24 00:00         79\n",
      "193263_6_time.npy                        2021-02-27 00:00   2021-05-08 00:00         70\n",
      "193263_7_time.npy                        2021-05-10 00:00   2021-06-05 00:00         26\n",
      "193263_8_time.npy                        2021-06-07 00:00   2021-07-16 00:00         39\n",
      "193263_9_time.npy                        2021-07-19 00:00   2021-09-24 00:00         67\n"
     ]
    }
   ],
   "source": [
    "# 1) 시간 벡터 파일 목록 불러오기\n",
    "time_files = sorted(glob.glob(\"T1_granada_time/193263_*_time.npy\"))\n",
    "\n",
    "# 2) 헤더 출력 (시작·종료 시각이 분 단위까지 보이도록 칼럼명 수정)\n",
    "print(f\"{'파일명':40s} {'시작시각':17s} {'종료시각':17s} {'엔트리수':>8s}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for fp in time_files:\n",
    "    # 3) numpy 로드 (python datetime.datetime 객체 배열 또는 numpy.datetime64 배열)\n",
    "    arr = np.load(fp, allow_pickle=True)\n",
    "\n",
    "    # 4) 시작·종료 시각 추출 (datetime.datetime 또는 numpy.datetime64)\n",
    "    start_dt = arr.min()\n",
    "    end_dt   = arr.max()\n",
    "\n",
    "    # 5) 엔트리 수\n",
    "    entry_count = len(arr)\n",
    "\n",
    "    # 6) 결과 출력: 분 단위까지 포맷팅\n",
    "    filename = os.path.basename(fp)\n",
    "    # 만약 arr 요소가 numpy.datetime64이면 to_pydatetime()으로 변환\n",
    "    if isinstance(start_dt, np.datetime64):\n",
    "        start_dt = start_dt.astype('M8[m]').astype('O')\n",
    "        end_dt   = end_dt.astype('M8[m]').astype('O')\n",
    "\n",
    "    print(f\"{filename:40s} \"\n",
    "          f\"{start_dt:%Y-%m-%d %H:%M}   \"\n",
    "          f\"{end_dt:%Y-%m-%d %H:%M}   \"\n",
    "          f\"{entry_count:8d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
